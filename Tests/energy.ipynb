{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Energy Path algtm to road photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = (0, 0, 255)\n",
    "\n",
    "MAX_ROAD_WIDTH = 275\n",
    "MAX_ROAD_X = 175\n",
    "\n",
    "MIN_ROAD_WIDTH = 75\n",
    "MIN_ROAD_X = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"C:\\Programs/facultate/licenta/my-autonomous-car/resources/fullCurve.png\")\n",
    "\n",
    "IMG_WIDTH = img.shape[1]\n",
    "IMG_HEIGHT = img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[207 212 209]\n",
      "  [220 225 222]\n",
      "  [224 230 225]\n",
      "  ...\n",
      "  [104 109 108]\n",
      "  [107 111 111]\n",
      "  [111 116 115]]\n",
      "\n",
      " [[201 207 203]\n",
      "  [224 230 226]\n",
      "  [222 228 223]\n",
      "  ...\n",
      "  [175 180 179]\n",
      "  [175 180 179]\n",
      "  [174 179 178]]\n",
      "\n",
      " [[181 187 184]\n",
      "  [227 232 229]\n",
      "  [224 230 225]\n",
      "  ...\n",
      "  [185 189 189]\n",
      "  [183 188 187]\n",
      "  [181 186 185]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 66  70  64]\n",
      "  [ 66  70  64]\n",
      "  [ 66  70  64]\n",
      "  ...\n",
      "  [ 56  60  56]\n",
      "  [ 56  60  55]\n",
      "  [ 56  60  55]]\n",
      "\n",
      " [[ 66  70  64]\n",
      "  [ 66  70  64]\n",
      "  [ 66  70  64]\n",
      "  ...\n",
      "  [ 56  60  56]\n",
      "  [ 56  60  55]\n",
      "  [ 56  60  55]]\n",
      "\n",
      " [[ 66  70  64]\n",
      "  [ 66  70  64]\n",
      "  [ 66  70  64]\n",
      "  ...\n",
      "  [ 56  60  56]\n",
      "  [ 56  60  55]\n",
      "  [ 56  60  55]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv2.imshow(\"original\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow(\"gray\",gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(gray,(3,3),3)\n",
    "\n",
    "cv2.imshow(\"blurred\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral blur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilateralBlurred = cv2.bilateralFilter(gray, 11, 21, 7)\n",
    "\n",
    "cv2.imshow(\"bilateral Blurred\",bilateralBlurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(gray,(3,3),3)\n",
    "bilateralBlurred = cv2.bilateralFilter(gray, 11, 21, 7)\n",
    "\n",
    "cv2.imshow(\"bilateral Blurred\",bilateralBlurred)\n",
    "\n",
    "\n",
    "cv2.imshow(\"blurred\",blurred)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic binary thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshClassis = cv2.threshold(blurred, 170, 255, cv2.THRESH_BINARY)\n",
    "# cv2.imwrite(\"classicTresh.jpg\",threshClassis)\n",
    "cv2.imshow(\"classic thresh\",threshClassis)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otsu's thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.0\n"
     ]
    }
   ],
   "source": [
    "T, threshOtsu = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "# cv2.imwrite(\"classicTresh.jpg\",threshClassis)\n",
    "print(T)\n",
    "cv2.imshow(\"classic thresh\",threshOtsu)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive binary thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshAdap = cv2.adaptiveThreshold(blurred, 255,\n",
    "\tcv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 5, 10)\n",
    "\n",
    "cv2.imshow(\"adaptive thresh\",threshAdap)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(gray,(5,5),0)\n",
    "# blurred = cv2.equalizeHist(blurred)\n",
    "\n",
    "# threshAdap = cv2.adaptiveThreshold(blurred, 255,\n",
    "#     cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "_, threshClassis = cv2.threshold(blurred, 170, 255, cv2.THRESH_BINARY)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "closed = cv2.morphologyEx(threshClassis, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"blurred\",closed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morphological ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "closing = cv2.morphologyEx(threshClassis, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"closed img\",closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(threshClassis, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow(\"opened img\",opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, threshClassis = cv2.threshold(blurred, 185, 255, cv2.THRESH_BINARY)\n",
    "# kernel = np.ones((3,3),np.uint8)\n",
    "kernel = cv2.getGaussianKernel(5,5)\n",
    "closing = cv2.morphologyEx(threshClassis, cv2.MORPH_CLOSE, kernel)\n",
    "opening = cv2.morphologyEx(threshClassis, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# cv2.imwrite(\"classicTresh.jpg\",threshClassis)\n",
    "cv2.imshow(\"classic thresh\",threshClassis)\n",
    "cv2.imshow(\"opened img\",opening)\n",
    "cv2.imshow(\"closed img\",closing)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(gray,(3,3),0)\n",
    "cv2.imshow(\"blur clasic img\",blurred)\n",
    "bilateralBlurred = cv2.bilateralFilter(gray, 11, 21, 7)\n",
    "cv2.imshow(\"blur bilateral img\",bilateralBlurred)\n",
    "_, threshClassis = cv2.threshold(blurred, 185, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"thresh clasic  + blurimg\",threshClassis)\n",
    "_, threshClassis = cv2.threshold(bilateralBlurred, 185, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"thresh clasic + biblur img\",threshClassis)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "closing = cv2.morphologyEx(threshClassis, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"closed img\",closing)\n",
    "kernel1 = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(threshClassis, cv2.MORPH_OPEN, kernel1)\n",
    "# cv2.imshow(\"opened img\",opening)\n",
    "kernel2 = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(closing, cv2.MORPH_OPEN, kernel2)\n",
    "# cv2.imshow(\"both img\",opening)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy(img):\n",
    "    \"\"\"\n",
    "    calculeaza energia la fiecare pixel pe baza gradientului\n",
    "    :param img: imaginea initiala\n",
    "    :return:E - energia\n",
    "    \"\"\"\n",
    "    # urmati urmatorii pasi:\n",
    "    # 1. transformati imagine in grayscale\n",
    "    # 2. folositi filtru sobel pentru a calcula gradientul in directia X si Y\n",
    "    # 3. calculati magnitudinea pentru fiecare pixel al imaginii\n",
    "    E = np.zeros((img.shape[0],img.shape[1]))\n",
    "    # img_grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    grad_x = cv2.Sobel(img,ddepth=cv2.CV_16S,dx=1,dy=0)\n",
    "    grad_y = cv2.Sobel(img,ddepth=cv2.CV_16S,dx=0,dy=1)\n",
    "\n",
    "    abs_x = np.abs(grad_x)\n",
    "    abs_y = np.abs(grad_y)\n",
    "\n",
    "    E = abs_x + abs_y\n",
    "\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_energy_v2(img):\n",
    "    ksize = 3\n",
    "\n",
    "    gX = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=ksize)\n",
    "    gY = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=0, dy=1, ksize=ksize)\n",
    "\n",
    "    gX = cv2.convertScaleAbs(gX)\n",
    "    gY = cv2.convertScaleAbs(gY)\n",
    "\n",
    "    # combined = cv2.addWeighted(gX, 0.5, gY, 0.5, 0)\n",
    "\n",
    "    magnitude = np.sqrt((gX ** 2) + (gY ** 2))\n",
    "    # magnitude = gX + gY\n",
    "\n",
    "    return magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = compute_energy_v2(threshClassis)\n",
    "\n",
    "# cv2.imshow(\"pre\", pre)\n",
    "# cv2.imshow(\"Sobel/Scharr Combined\", combined)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = compute_energy(opening)\n",
    "cv2.imshow(\"gradient img\",gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dynamic_programming_path_going_up(E):\n",
    "    M = np.zeros(E.shape)\n",
    "    M[0,:] = E[0,:]\n",
    "    for i in range(1,E.shape[0]):\n",
    "        for j  in range (E.shape[1]):\n",
    "            if j == 0:\n",
    "                M[i][j] = E[i,j]+max(M[i-1,0],M[i-1,1])\n",
    "            elif j == E.shape[1] - 1:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j],M[i-1,j-1])\n",
    "            else:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j+1],M[i-1,j],M[i-1,j-1])\n",
    "    line = M.shape[0] - 1\n",
    "    col = np.argmax(M[line,:])\n",
    "    # print(np.max(M[line,:]))\n",
    "    path = [0 for i in range(line+1)]\n",
    "\n",
    "    path[line] = (line,col)\n",
    "    \n",
    "    for line in range(M.shape[0]-2,-1,-1):\n",
    "        if col == 0:\n",
    "            if M[line,0] < M[line,1]:\n",
    "                new_col = 1\n",
    "            else:\n",
    "                new_col = 0\n",
    "        elif col == E.shape[1] - 1:\n",
    "            if M[line,col] < M[line,col-1]:\n",
    "                new_col = col - 1\n",
    "            else:\n",
    "                new_col = col\n",
    "        else:\n",
    "            neigh = np.array([M[line,col-1],M[line,col],M[line,col+1]])\n",
    "            new_col = col+np.argmax(neigh) - 1\n",
    "\n",
    "        path[line]= (line,new_col)\n",
    "\n",
    "        col = new_col\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dynamic_programming_path_going_sideways(E):\n",
    "    M = np.zeros(E.shape)\n",
    "    M[0,:] = E[0,:]\n",
    "    for i in range(1,E.shape[0]):\n",
    "        for j  in range (E.shape[1]):\n",
    "            if j == 0:\n",
    "                M[i][j] = E[i,j]+max(M[i-1,0],M[i-1,1])\n",
    "            elif j == E.shape[1] - 1:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j],M[i-1,j-1])\n",
    "            else:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j+1],M[i-1,j],M[i-1,j-1],M[i][j+1],M[i][j-1])\n",
    "    line = M.shape[0] - 1\n",
    "    col = np.argmax(M[line,:])\n",
    "    # print(np.max(M[line,:]))\n",
    "    path = [0 for _ in range(60)]\n",
    "    # path = []\n",
    "    index = 0\n",
    "\n",
    "    path[index] = (line,col)\n",
    "\n",
    "    lineIndex = M.shape[0]-1\n",
    "    nextLine = False\n",
    "    while lineIndex > 0 and col >= 0 and col < M.shape[1] and index != 50:\n",
    "        if col == 0:\n",
    "            # if M[lineIndex,0] < M[lineIndex,1]:\n",
    "            #     new_col = 1\n",
    "            #     nextLine = False\n",
    "            # else:\n",
    "            #     new_col = 0\n",
    "            #     nextLine = False\n",
    "            if M[lineIndex-1,0] < M[lineIndex-1,1]:\n",
    "                new_col = 1\n",
    "                nextLine = True\n",
    "            else:\n",
    "                new_col = 0\n",
    "                nextLine = True\n",
    "        elif col == E.shape[1] - 1:\n",
    "            if M[lineIndex-1,col] < M[lineIndex-1,col-1]:\n",
    "                new_col = col - 1\n",
    "                nextLine = True\n",
    "            else:\n",
    "                new_col = col\n",
    "                nextLine = True\n",
    "        else:\n",
    "            same_line = np.array([M[lineIndex,col-1],M[lineIndex,col+1]])\n",
    "            upper_line = np.array([M[lineIndex-1,col-1],M[lineIndex-1,col],M[lineIndex-1,col+1]])\n",
    "            if np.max(same_line) > np.max(upper_line):\n",
    "                new_col = col+np.argmax(same_line) - 1\n",
    "                nextLine = False\n",
    "            else:\n",
    "                new_col = col+np.argmax(upper_line) - 1\n",
    "                nextLine = True\n",
    "\n",
    "        if nextLine:\n",
    "            lineIndex -= 1\n",
    "\n",
    "        index += 1  \n",
    "        path[index]= (lineIndex,new_col)\n",
    "\n",
    "        col = new_col\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0),\n",
       "       (0, 0), (0, 0)], dtype=[('x', '<u2'), ('y', '<u2')])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = [('x', 'uint16'), ('y', 'uint16')]  # specifying tuple structure as a list of pairs\n",
    "np_array_of_tuples = np.zeros(10, dtype=dtype)\n",
    "np_array_of_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_dynamic_programming_border_going_up_point_start(E,point): #TODO Sa incerc sa tin pathul in interiorul benzii si sa nu fac pe 2 imagini diferite    \n",
    "    M = np.zeros(E.shape)\n",
    "    M[0,:] = E[0,:]\n",
    "    for i in range(1,E.shape[0]):\n",
    "        for j  in range (E.shape[1]):\n",
    "            if j == 0:\n",
    "                M[i][j] = E[i,j]+max(M[i-1,0],M[i-1,1])\n",
    "            elif j == E.shape[1] - 1:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j],M[i-1,j-1])\n",
    "            elif j >= 2 and j <= E.shape[1] - 3:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j+1],M[i-1,j],M[i-1,j-1],M[i-1,j-2],M[i-1,j+2])\n",
    "            else:\n",
    "                M[i,j] = E[i,j]+max(M[i-1,j+1],M[i-1,j],M[i-1,j-1])\n",
    "    line = M.shape[0] - 1\n",
    "    # col = np.argmax(M[line,:])\n",
    "    col = point\n",
    "    # print(np.max(M[line,:]))\n",
    "    # path = [(0,0) for i in range(line+1)]\n",
    "\n",
    "    dtype = [('x', 'uint16'), ('y', 'uint16')]\n",
    "    path = np.zeros(line+1, dtype=dtype)\n",
    "\n",
    "    path[line] = (line,point)\n",
    "\n",
    "    direction = point\n",
    "    \n",
    "    for line in range(M.shape[0]-2,60,-1):\n",
    "        if col == 0:\n",
    "            if M[line,0] < M[line,1]:\n",
    "                new_col = 1\n",
    "            else:\n",
    "                new_col = 0\n",
    "        elif col == E.shape[1] - 1:\n",
    "            if M[line,col] < M[line,col-1]:\n",
    "                new_col = col - 1\n",
    "            else:\n",
    "                new_col = col\n",
    "        elif col >= 2 and col <= E.shape[1] - 3:\n",
    "            if not (M[line,col-1] == M[line,col] == M[line,col+1] == M[line,col-2] == M[line,col+2]):\n",
    "                neigh = np.array([M[line,col-2],M[line,col-1],M[line,col],M[line,col+1],M[line,col+2]]) #TODO proiectia parcursului actual al masinii cu unghiul actual al rotilor\n",
    "                new_col = col+np.argmax(neigh) - 2\n",
    "            else:\n",
    "                new_col = col - (direction - col)\n",
    "                # new_col = col\n",
    "                # if M[line,new_col] == 0 and new_col > 0:\n",
    "                #     new_col -= 1\n",
    "        else:\n",
    "            if not (M[line,col-1] == M[line,col] == M[line,col+1]):\n",
    "                neigh = np.array([M[line,col-1],M[line,col],M[line,col+1]]) #TODO proiectia parcursului actual al masinii cu unghiul actual al rotilor\n",
    "                new_col = col+np.argmax(neigh) - 1\n",
    "            else:\n",
    "                new_col = col - (direction - col)\n",
    "        # if col - 1 > 1 and col + 1 < E.shape[1] - 2:\n",
    "        #     print(M[line,col-2],M[line,col-1],M[line,col],M[line,col+1],M[line,col+2],end=\" \")\n",
    "        #     print(line,end=\" \")\n",
    "        #     print(new_col)\n",
    "        direction = col\n",
    "\n",
    "        path[line]= (line,new_col)\n",
    "\n",
    "        col = new_col\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_path(img, path, color):\n",
    "    \n",
    "    new_image = img.copy()\n",
    "\n",
    "    for row, col in path:\n",
    "        if col and col < img.shape[1]:\n",
    "            new_image[row, col] = color\n",
    "            \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(gray,(3,3),0)\n",
    "\n",
    "    _, threshClassis = cv2.threshold(blurred, 190, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # kernel = cv2.getStructuringElement(cv2.MORPH_DILATE, (15, 15))\n",
    "    # closing = cv2.morphologyEx(threshClassis, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return threshClassis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = preprocess(img)\n",
    "preL = pre[:,:int(pre.shape[1]/2)]\n",
    "preR = pre[:,int(pre.shape[1]/2):]\n",
    "cv2.imshow('PreR', preR)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = preprocess(img)\n",
    "grad = compute_energy(pre)\n",
    "cv2.imshow('Pre', pre)\n",
    "cv2.imshow('grad', grad)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lane_start(img):\n",
    "    histogram = np.sum(img[img.shape[0] // 2:, :], axis = 0)\n",
    "\n",
    "    midpoint = int(histogram.shape[0] / 2)\n",
    "\n",
    "    leftxBase = np.argmax(histogram[:midpoint])\n",
    "    rightxBase = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    return leftxBase,rightxBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bordering going always up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_borders(preprocImg):\n",
    "    \n",
    "    leftxBase,rightxBase = get_lane_start(preprocImg)\n",
    "\n",
    "    preprocImg[:20,:] = 0\n",
    "\n",
    "    gradientImg = compute_energy_v2(preprocImg)\n",
    "\n",
    "    borderL = select_dynamic_programming_border_going_up_point_start(gradientImg,leftxBase)\n",
    "    borderR = select_dynamic_programming_border_going_up_point_start(gradientImg,rightxBase)\n",
    "    # print(pathL)\n",
    "    # print(pathR)\n",
    "\n",
    "    return borderL,borderR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_width(y):\n",
    "    return w1 + (MIN_ROAD_WIDTH - MAX_ROAD_WIDTH) / (min - y1) * (y - y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(borderL,borderR):\n",
    "    for yL,yR in zip(borderL,borderR):\n",
    "        if yR[1] - yL[1] < MIN_ROAD_WIDTH:\n",
    "            if yL[1] > IMG_WIDTH//2:\n",
    "                yL[1] = 0\n",
    "                yR[1] += 0\n",
    "            elif yR[1] <  IMG_WIDTH //2:\n",
    "                yR[1] = 0\n",
    "    # path[:, 1] = np.where(path[:, 1] < 240, 0, path[:, 1])\n",
    "    path = np.array([(x, (yR + yL)//2) for (x, yL), (_, yR) in zip(borderL, borderR)])\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_deviation_simple(path,img):\n",
    "\n",
    "    lane_center_x = (path[-1][0],path[0][0])\n",
    "    # lane_center_x[1] = path[-1][0]\n",
    "\n",
    "    lane_center_y = (path[-1][1],path[0][1])\n",
    "    # lane_center_y[1] = path[-1][1]\n",
    "\n",
    "    car_position = (160, 240)  # Car's position (x_c, y_c)\n",
    "    car_heading = (1, 1)\n",
    "\n",
    "    car_direction_end = (\n",
    "        int(car_position[0] + car_heading[0] * 100),\n",
    "        int(car_position[1] + car_heading[1] * 100),\n",
    "    )\n",
    "\n",
    "    print(lane_center_x)\n",
    "\n",
    "    lane_start = (int(lane_center_x[0]), int(lane_center_y[0]))\n",
    "    lane_end = (int(lane_center_x[-1]), int(lane_center_y[-1]))\n",
    "\n",
    "    print(lane_start,lane_end)\n",
    "\n",
    "    cv2.line(img, (0,0), (100,100), color=(0, 255, 255), thickness=1)\n",
    "\n",
    "    # cv2.line(img, car_position, car_direction_end, color=(0, 0, 255), thickness=2)\n",
    "\n",
    "    # Draw the car's position\n",
    "    # cv2.circle(img, car_position, radius=5, color=(0, 255, 0), thickness=-1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61 231]\n",
      " [ 62 231]\n",
      " [ 63 231]\n",
      " [ 64 231]\n",
      " [ 65 232]\n",
      " [ 66 232]\n",
      " [ 67 232]\n",
      " [ 68 232]\n",
      " [ 69 232]\n",
      " [ 70 233]\n",
      " [ 71 232]\n",
      " [ 72 232]\n",
      " [ 73 233]\n",
      " [ 74 233]\n",
      " [ 75 233]\n",
      " [ 76 234]\n",
      " [ 77 234]\n",
      " [ 78 234]\n",
      " [ 79 234]\n",
      " [ 80 234]\n",
      " [ 81 235]\n",
      " [ 82 235]\n",
      " [ 83 235]\n",
      " [ 84 235]\n",
      " [ 85 235]\n",
      " [ 86 236]\n",
      " [ 87 236]\n",
      " [ 88 236]\n",
      " [ 89 236]\n",
      " [ 90 237]\n",
      " [ 91 237]\n",
      " [ 92 237]\n",
      " [ 93 238]\n",
      " [ 94 238]\n",
      " [ 95 238]\n",
      " [ 96 238]\n",
      " [ 97 238]\n",
      " [ 98 239]\n",
      " [ 99 239]\n",
      " [100 239]\n",
      " [101 239]\n",
      " [102 240]\n",
      " [103 240]\n",
      " [104 240]\n",
      " [105 240]\n",
      " [106 240]\n",
      " [107 241]\n",
      " [108 241]\n",
      " [109 241]\n",
      " [110 242]\n",
      " [111 241]\n",
      " [112 242]\n",
      " [113 242]\n",
      " [114 242]\n",
      " [115 242]\n",
      " [116 242]\n",
      " [117 243]\n",
      " [118 243]\n",
      " [119 243]\n",
      " [120 243]\n",
      " [121 243]\n",
      " [122 243]\n",
      " [123 243]\n",
      " [124 243]\n",
      " [125 244]\n",
      " [126 244]\n",
      " [127 244]\n",
      " [128 244]\n",
      " [129 245]\n",
      " [130 245]\n",
      " [131 245]\n",
      " [132 245]\n",
      " [133 245]\n",
      " [134 246]\n",
      " [135 246]\n",
      " [136 246]\n",
      " [137 246]\n",
      " [138 246]\n",
      " [139 246]\n",
      " [140 246]\n",
      " [141 247]\n",
      " [142 247]\n",
      " [143 247]\n",
      " [144 247]\n",
      " [145 247]\n",
      " [146 247]\n",
      " [147 248]\n",
      " [148 248]\n",
      " [149 248]\n",
      " [150 248]\n",
      " [151 248]\n",
      " [152 248]\n",
      " [153 249]\n",
      " [154 249]\n",
      " [155 249]\n",
      " [156 249]\n",
      " [157 249]\n",
      " [158 249]\n",
      " [159 249]\n",
      " [160 250]\n",
      " [161 250]\n",
      " [162 250]\n",
      " [163 250]\n",
      " [164 250]\n",
      " [165 250]\n",
      " [166 251]\n",
      " [167 251]\n",
      " [168 250]\n",
      " [169 251]\n",
      " [170 251]\n",
      " [171 251]\n",
      " [172 251]\n",
      " [173 252]\n",
      " [174 252]\n",
      " [175 252]\n",
      " [176 252]\n",
      " [177 252]\n",
      " [178 252]\n",
      " [179 252]\n",
      " [180 252]\n",
      " [181 252]\n",
      " [182 252]\n",
      " [183 253]\n",
      " [184 252]\n",
      " [185 253]\n",
      " [186 253]\n",
      " [187 253]\n",
      " [188 254]\n",
      " [189 253]\n",
      " [190 254]\n",
      " [191 254]\n",
      " [192 254]\n",
      " [193 254]\n",
      " [194 254]\n",
      " [195 254]\n",
      " [196 255]\n",
      " [197 255]\n",
      " [198 255]\n",
      " [199 255]\n",
      " [200 255]\n",
      " [201 255]\n",
      " [202 256]\n",
      " [203 255]\n",
      " [204 256]\n",
      " [205 256]\n",
      " [206 256]\n",
      " [207 257]\n",
      " [208 256]\n",
      " [209 256]\n",
      " [210 257]\n",
      " [211 257]\n",
      " [212 257]\n",
      " [213 257]\n",
      " [214 257]\n",
      " [215 257]\n",
      " [216 257]\n",
      " [217 257]\n",
      " [218 258]\n",
      " [219 258]\n",
      " [220 258]\n",
      " [221 259]\n",
      " [222 258]\n",
      " [223 259]\n",
      " [224 259]\n",
      " [225 259]\n",
      " [226 259]\n",
      " [227 259]\n",
      " [228 259]\n",
      " [229 260]\n",
      " [230 260]\n",
      " [231 260]\n",
      " [232 260]\n",
      " [233 260]\n",
      " [234 260]\n",
      " [235 261]\n",
      " [236 261]\n",
      " [237 261]\n",
      " [238 261]\n",
      " [239 261]\n",
      " [240 261]\n",
      " [241 261]\n",
      " [242 261]\n",
      " [243 261]\n",
      " [244 262]\n",
      " [245 262]\n",
      " [246 262]\n",
      " [247 262]\n",
      " [248 262]\n",
      " [249 262]\n",
      " [250 263]\n",
      " [251 263]\n",
      " [252 263]\n",
      " [253 263]\n",
      " [254 263]\n",
      " [255 263]\n",
      " [256 264]\n",
      " [257 263]\n",
      " [258 264]\n",
      " [259 264]\n",
      " [260 264]\n",
      " [261 264]\n",
      " [262 264]\n",
      " [263 264]\n",
      " [264 265]\n",
      " [265 265]\n",
      " [266 265]\n",
      " [267 265]\n",
      " [268 265]\n",
      " [269 265]\n",
      " [270 266]\n",
      " [271 266]\n",
      " [272 266]\n",
      " [273 266]\n",
      " [274 266]\n",
      " [275 266]\n",
      " [276 267]\n",
      " [277 267]\n",
      " [278 267]\n",
      " [279 267]\n",
      " [280 267]\n",
      " [281 267]\n",
      " [282 268]\n",
      " [283 268]\n",
      " [284 268]\n",
      " [285 268]\n",
      " [286 268]\n",
      " [287 268]\n",
      " [288 269]\n",
      " [289 268]\n",
      " [290 269]\n",
      " [291 269]\n",
      " [292 269]\n",
      " [293 269]\n",
      " [294 269]\n",
      " [295 269]\n",
      " [296 270]\n",
      " [297 270]\n",
      " [298 270]\n",
      " [299 270]\n",
      " [300 270]\n",
      " [301 270]\n",
      " [302 271]\n",
      " [303 271]\n",
      " [304 271]\n",
      " [305 271]\n",
      " [306 271]\n",
      " [307 271]\n",
      " [308 271]\n",
      " [309 271]\n",
      " [310 271]\n",
      " [311 272]\n",
      " [312 272]\n",
      " [313 272]\n",
      " [314 272]\n",
      " [315 272]\n",
      " [316 273]\n",
      " [317 273]\n",
      " [318 273]\n",
      " [319 273]\n",
      " [320 273]\n",
      " [321 273]\n",
      " [322 273]\n",
      " [323 273]\n",
      " [324 274]\n",
      " [325 274]\n",
      " [326 274]\n",
      " [327 274]\n",
      " [328 274]\n",
      " [329 274]\n",
      " [330 275]\n",
      " [331 274]\n",
      " [332 275]\n",
      " [333 275]\n",
      " [334 275]\n",
      " [335 275]\n",
      " [336 275]\n",
      " [337 275]\n",
      " [338 276]\n",
      " [339 276]\n",
      " [340 276]\n",
      " [341 276]\n",
      " [342 276]\n",
      " [343 276]\n",
      " [344 277]\n",
      " [345 276]\n",
      " [346 277]\n",
      " [347 277]\n",
      " [348 277]\n",
      " [349 277]\n",
      " [350 277]\n",
      " [351 277]\n",
      " [352 278]\n",
      " [353 278]\n",
      " [354 278]\n",
      " [355 278]\n",
      " [356 278]\n",
      " [357 278]\n",
      " [358 278]\n",
      " [359 278]\n",
      " [360 279]\n",
      " [361 279]\n",
      " [362 279]\n",
      " [363 279]\n",
      " [364 279]\n",
      " [365 279]\n",
      " [366 280]\n",
      " [367 279]\n",
      " [368 280]\n",
      " [369 280]\n",
      " [370 280]\n",
      " [371 280]\n",
      " [372 281]\n",
      " [373 280]\n",
      " [374 281]\n",
      " [375 281]\n",
      " [376 281]\n",
      " [377 282]\n",
      " [378 281]\n",
      " [379 281]\n",
      " [380 282]\n",
      " [381 282]\n",
      " [382 282]\n",
      " [383 283]\n",
      " [384 282]\n",
      " [385 283]\n",
      " [386 283]\n",
      " [387 283]\n",
      " [388 283]\n",
      " [389 283]\n",
      " [390 283]\n",
      " [391 284]\n",
      " [392 284]\n",
      " [393 284]\n",
      " [394 284]\n",
      " [395 284]\n",
      " [396 284]\n",
      " [397 286]\n",
      " [398 287]\n",
      " [399 288]\n",
      " [400 290]\n",
      " [401 291]\n",
      " [402 293]\n",
      " [403 294]\n",
      " [404 295]\n",
      " [405 297]\n",
      " [406 298]\n",
      " [407 300]\n",
      " [408 300]\n",
      " [409 300]\n",
      " [410 300]\n",
      " [411 301]\n",
      " [412 301]\n",
      " [413 301]\n",
      " [414 301]\n",
      " [415 301]\n",
      " [416 302]\n",
      " [417 302]\n",
      " [418 302]\n",
      " [419 302]\n",
      " [420 302]\n",
      " [421 302]\n",
      " [422 303]\n",
      " [423 303]\n",
      " [424 303]\n",
      " [425 303]\n",
      " [426 303]\n",
      " [427 304]\n",
      " [428 304]\n",
      " [429 304]\n",
      " [430 304]\n",
      " [431 304]\n",
      " [432 305]\n",
      " [433 305]\n",
      " [434 305]\n",
      " [435 305]\n",
      " [436 306]\n",
      " [437 306]\n",
      " [438 306]\n",
      " [439 306]\n",
      " [440 306]\n",
      " [441 307]\n",
      " [442 307]\n",
      " [443 307]\n",
      " [444 308]\n",
      " [445 307]\n",
      " [446 308]\n",
      " [447 308]\n",
      " [448 308]\n",
      " [449 308]\n",
      " [450 309]\n",
      " [451 308]\n",
      " [452 309]\n",
      " [453 309]\n",
      " [454 309]\n",
      " [455 310]\n",
      " [456 310]\n",
      " [457 310]\n",
      " [458 310]\n",
      " [459 310]\n",
      " [460 311]\n",
      " [461 311]\n",
      " [462 311]\n",
      " [463 311]\n",
      " [464 312]\n",
      " [465 311]\n",
      " [466 312]\n",
      " [467 312]\n",
      " [468 312]\n",
      " [469 313]\n",
      " [470 313]\n",
      " [471 313]\n",
      " [472 313]\n",
      " [473 313]\n",
      " [474 313]\n",
      " [475 314]\n",
      " [476 314]\n",
      " [477 314]\n",
      " [478 315]\n",
      " [479 316]]\n",
      "(np.uint16(479), np.uint16(61))\n",
      "(479, 316) (61, 231)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"fullNewTrack.jpg\")\n",
    "preprocImg = preprocess(image)\n",
    "\n",
    "borderL,borderR = find_borders(preprocImg)\n",
    "# for yL,yR in zip(borderL,borderR):\n",
    "#     print(yR)\n",
    "borderedImgL = draw_path(image,borderL,RED)\n",
    "borderedImg = draw_path(borderedImgL,borderR,RED)\n",
    "\n",
    "path = find_path(borderL,borderR)\n",
    "# print(path)\n",
    "filtered_path = path[~np.all(path == 0, axis=1)]\n",
    "print(filtered_path)\n",
    "pathImg = draw_path(image,path,RED)\n",
    "# determine_deviation_simple(path,img)\n",
    "imgCopy = image.copy()\n",
    "imgDirection = determine_deviation_simple(filtered_path,imgCopy)\n",
    "cv2.imshow('imgDirection', imgDirection)\n",
    "# cv2.imwrite(\"testStraight.jpg\",borderedImg)\n",
    "cv2.imshow('pathImg', pathImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\AppData\\Local\\Temp\\ipykernel_21924\\3489857677.py:3: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  if yR[1] - yL[1] < MIN_ROAD_WIDTH:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 319) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 318) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 317) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 319) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 319) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 319) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 317) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 317) (0, 0)\n",
      "(np.uint16(479), np.uint16(0))\n",
      "(479, 319) (0, 0)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('newCameraRodNewTrack.mp4')\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # pre = preprocess(frame)\n",
    "    # leftxBase,rightxBase = get_lane_start(pre)\n",
    "    # pre[:20,:] = 0\n",
    "    # cv2.imshow(\"grad Image\",pre)\n",
    "    # grad = compute_energy_v2(pre)\n",
    "    # pathL = select_dynamic_programming_border_going_up_point_start(grad,leftxBase)\n",
    "    # pathR = select_dynamic_programming_border_going_up_point_start(grad,rightxBase)\n",
    "    # path = find_path(borderL,borderR)\n",
    "    # new_img = draw_path(frame,pathL,pathR,RED) \n",
    "    # cv2.imshow('newImg', new_img)\n",
    "\n",
    "    preprocImg = preprocess(frame)\n",
    "    cv2.imshow('preprocImg', preprocImg)\n",
    "\n",
    "    borderL,borderR = find_borders(preprocImg) \n",
    "    # for yL,yR in zip(borderL,borderR):\n",
    "    #     print(yR)\n",
    "    borderedImgL = draw_path(frame,borderL,RED)\n",
    "    borderedImg = draw_path(borderedImgL,borderR,RED)\n",
    "\n",
    "    path = find_path(borderL,borderR)\n",
    "    # print(path)\n",
    "    pathImg = draw_path(borderedImg,path,RED)\n",
    "    # cv2.imshow('borderedImg', borderedImg)\n",
    "    # cv2.imwrite(\"testStraight.jpg\",borderedImg)\n",
    "    cv2.imshow('pathImg', pathImg)\n",
    "    direction = determine_deviation_simple(path,frame)\n",
    "    # cv2.imshow('direction', direction)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raspberry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
